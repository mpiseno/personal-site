<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Michael  Piseno | Facebook AI Research</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.png">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/facebook/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Michael</span>   Piseno
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/experience/">
                experience
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Facebook AI Research</h1>
    <p class="post-description">Winter 2020</p>
  </header>

  <article>
    <h2 id="habitat-a-platform-for-embodied-ai-research">Habitat: A Platform for Embodied AI Research</h2>

<p><a href="https://aihabitat.org/">Habitat</a> is a platform for embodied AI research. Embodied AI is the study of intelligent systems that have a physical or virtual embodiment. Robots are a common example of embodied AI, as they physically move around and make complex decisions within their environments.</p>

<center>
    <img src="/assets/img/projects/facebook/habitat.gif" style="width: 80%; padding: 5%" />
</center>

<p>Habitat was created by Facebook AI Research (FAIR) to excellerate research in embodied AI. It comes with several indoor environments, popular algorithms implemented as baselines such as PPO and TRPO, and an annual challenge, the “Habitat Challenge”, which was created to benchmark and accelerate progress in embodied AI. I interned on the Habitat team at FAIR in Winter 2020 where I developed a research tool for extracting images from within Habitat environments.</p>

<h2 id="image-extractor">Image Extractor</h2>

<p>Generating and labelling real world image data is time consuming and expensive. Using Habitat to automatically generate images from within Habitat’s virtual environments provides researchers with a much cheaper and easier option, as the images already come with semantic labels.</p>

<p>Using the image extractor is very simple - you only need to provide the constructor with a filepath to the meshfile used for the environment. Here is a short example of instantiating an image extractor and displaying a few RGB, depth, and semantic images:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">habitat_sim.utils.data</span> <span class="kn">import</span> <span class="n">ImageExtractor</span>


<span class="c1"># For viewing the extractor output
</span><span class="k">def</span> <span class="nf">display_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"rgba"</span><span class="p">]</span>
    <span class="n">depth</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"depth"</span><span class="p">]</span>
    <span class="n">semantic</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">"semantic"</span><span class="p">]</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="p">[</span><span class="n">img</span><span class="p">,</span> <span class="n">depth</span><span class="p">,</span> <span class="n">semantic</span><span class="p">]</span>
    <span class="n">titles</span> <span class="o">=</span> <span class="p">[</span><span class="s">"rgba"</span><span class="p">,</span> <span class="s">"depth"</span><span class="p">,</span> <span class="s">"semantic"</span><span class="p">]</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">arr</span><span class="p">):</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">titles</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">scene_filepath</span> <span class="o">=</span> <span class="s">"data/scene_datasets/habitat-test-scenes/apartment_1.glb"</span>

<span class="n">extractor</span> <span class="o">=</span> <span class="n">ImageExtractor</span><span class="p">(</span>
    <span class="n">scene_filepath</span><span class="p">,</span>
    <span class="n">img_size</span><span class="o">=</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>
    <span class="n">output</span><span class="o">=</span><span class="p">[</span><span class="s">"rgba"</span><span class="p">,</span> <span class="s">"depth"</span><span class="p">,</span> <span class="s">"semantic"</span><span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Index in to the extractor like a normal python list
</span><span class="n">sample</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Or use slicing
</span><span class="n">samples</span> <span class="o">=</span> <span class="n">extractor</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
    <span class="n">display_sample</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

<span class="c1"># Close the extractor so we can instantiate another one later
# (see close method for detailed explanation)
</span><span class="n">extractor</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></div>

<p>Output:</p>

<center>
    <img src="/assets/img/projects/facebook/extractor-example-output.png" style="max-width: 80%;" />
</center>

<h2 id="use-case-semantic-segmentation">Use Case: Semantic Segmentation</h2>

<p>As a proof of concept for using the image extractor to solve a task involving image data, I created an end-to-end data pipeline for learning a semantic segmentation task on indoor image data using UNet, a popular architecture for semantic segmentation. Here is an example of incorporating the image extractor into <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">PyTorch Datasets and Dataloaders</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">ToTensor</span>

<span class="kn">from</span> <span class="nn">habitat_sim.utils.data</span> <span class="kn">import</span> <span class="n">ImageExtractor</span>


<span class="c1"># Replace with the path to your scene file
</span><span class="n">SCENE_FILEPATH</span> <span class="o">=</span> <span class="s">'data/scene_datasets/habitat-test-scenes/apartment_0/mesh.ply'</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">class</span> <span class="nc">SemanticSegmentationDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extractor</span><span class="p">,</span> <span class="n">transforms</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="c1"># Define an ImageExtractor
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">extractor</span> <span class="o">=</span> <span class="n">extractor</span>

        <span class="c1"># We will perform preprocessing transforms on the data
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span>

        <span class="c1"># Habitat sim outputs instance id's from the semantic sensor (i.e. two
</span>        <span class="c1"># different chairs will be marked with different id's). So we need
</span>        <span class="c1"># to create a mapping from these instance id to the class labels we
</span>        <span class="c1"># want to predict. We will use the below dictionaries to define a
</span>        <span class="c1"># funtion that takes the raw output of the semantic sensor and creates
</span>        <span class="c1"># a 2d numpy array of out class labels.
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'background'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">'wall'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s">'floor'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s">'ceiling'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s">'chair'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s">'table'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">instance_id_to_name</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">extractor</span><span class="p">.</span><span class="n">instance_id_to_name</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">map_to_class_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">labels</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">instance_id_to_name</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">extractor</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">extractor</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">raw_semantic_output</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="s">'semantic'</span><span class="p">]</span>
        <span class="n">truth_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_class_labels</span><span class="p">(</span><span class="n">raw_semantic_output</span><span class="p">)</span>

        <span class="n">output</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'rgb'</span><span class="p">:</span> <span class="n">sample</span><span class="p">[</span><span class="s">'rgba'</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">],</span>
            <span class="s">'truth'</span><span class="p">:</span> <span class="n">truth_mask</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">:</span>
            <span class="n">output</span><span class="p">[</span><span class="s">'rgb'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s">'rgb'</span><span class="p">])</span>
            <span class="n">output</span><span class="p">[</span><span class="s">'truth'</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transforms</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s">'truth'</span><span class="p">]).</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">get_class_labels</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_semantic_output</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">map_to_class_labels</span><span class="p">(</span><span class="n">raw_semantic_output</span><span class="p">)</span>


<span class="n">extractor</span> <span class="o">=</span> <span class="n">ImageExtractor</span><span class="p">(</span><span class="n">SCENE_FILEPATH</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="p">[</span><span class="s">'rgba'</span><span class="p">,</span> <span class="s">'semantic'</span><span class="p">])</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">SemanticSegmentationDataset</span><span class="p">(</span><span class="n">extractor</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="n">transforms</span><span class="p">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="p">.</span><span class="n">ToTensor</span><span class="p">()])</span>
<span class="p">)</span>

<span class="c1"># Create a Dataloader to batch and shuffle our data
</span><span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>The full code for this example can be seen in the image extractor <a href="https://aihabitat.org/docs/habitat-sim/image-extractor.html">documentation</a>. Here are the results for overfitting on a small subset of images extracted from the <a href="https://github.com/facebookresearch/Replica-Dataset">Replica Dataset</a>:</p>

<center>
    <img src="/assets/img/projects/facebook/semantic-segmentation-results.png" style="max-width: 80%;" />
</center>

<p>The top row contains RGB images from within Habitat. The middle row is the ground-truth semantic mask. The bottom row is the model’s predicted semantic mask.</p>

<h2 id="conclusion">Conclusion</h2>

<p>My internship at FAIR was a fantastic learning experience, as I collaborated with researchers and engineers to develop a useful research tool and documented it extensively. Make sure to check out the full <a href="https://aihabitat.org/docs/habitat-sim/image-extractor.html">docs</a> for an in-depth look at the image extractor API and semantic segmentation example!</p>


  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Michael  Piseno.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
